{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence=\"This is the text which I will be using to learn about Embeddings, Transformer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'about': 0,\n",
       " 'be': 1,\n",
       " 'embeddings': 2,\n",
       " 'i': 3,\n",
       " 'is': 4,\n",
       " 'learn': 5,\n",
       " 'text': 6,\n",
       " 'the': 7,\n",
       " 'this': 8,\n",
       " 'to': 9,\n",
       " 'transformer': 10,\n",
       " 'using': 11,\n",
       " 'which': 12,\n",
       " 'will': 13}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc={v:k for k,v in enumerate(sorted(sentence.replace(\",\",\"\").lower().split()))}\n",
    "dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8,  4,  7,  6, 12,  3, 13,  1, 11,  9,  5,  0,  2, 10])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_emb=[]\n",
    "for i in sentence.replace(\",\",\"\").lower().split():\n",
    "    sentence_emb.append(dc[i])\n",
    "sentence_input=torch.tensor(sentence_emb)\n",
    "sentence_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.2791,  1.2964,  0.6105],\n",
       "        [-0.7279, -0.5594, -0.7688],\n",
       "        [ 1.0783,  0.8008,  1.6806],\n",
       "        [-0.4974,  0.4396, -0.7581],\n",
       "        [ 0.3189, -0.4245,  0.3057],\n",
       "        [ 1.6487, -0.3925, -1.4036],\n",
       "        [-0.7746, -1.5576,  0.9956],\n",
       "        [-2.1055,  0.6784, -1.2345],\n",
       "        [-0.8712, -0.2234,  1.7174],\n",
       "        [ 1.3347, -0.2316,  0.0418],\n",
       "        [ 0.7624,  1.6423, -0.1596],\n",
       "        [ 1.9269,  1.4873,  0.9007],\n",
       "        [-0.0431, -1.6047, -0.7521],\n",
       "        [-0.2516,  0.8599, -1.3847]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size=50000\n",
    "torch.manual_seed(42)\n",
    "embed=torch.nn.Embedding(vocab_size,3)\n",
    "embedded_sentence=embed(sentence_input).detach()\n",
    "embedded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.5485,  2.1001],\n",
       "        [-1.4484, -1.3787],\n",
       "        [ 2.3276,  2.3570],\n",
       "        [-0.3269, -0.7611],\n",
       "        [ 0.0100,  0.3239],\n",
       "        [ 0.5581,  0.5850],\n",
       "        [-1.7274, -0.7529],\n",
       "        [-1.7095, -2.4968],\n",
       "        [-0.3155,  0.1090],\n",
       "        [ 0.9816,  1.2151],\n",
       "        [ 2.1143,  1.2768],\n",
       "        [ 3.4058,  2.9704],\n",
       "        [-1.7942, -1.1198],\n",
       "        [ 0.0347, -0.7377]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "d=embedded_sentence.size()[-1]\n",
    "d_q,d_k,d_v=2,2,4\n",
    "W_q=torch.nn.Parameter(torch.rand(d_q,d))\n",
    "w_k=torch.nn.Parameter(torch.rand(d_k,d))\n",
    "w_v=torch.nn.Parameter(torch.rand(d_v,d))\n",
    "q=embedded_sentence@W_q.T\n",
    "k=embedded_sentence@w_k.T\n",
    "v=embedded_sentence@w_v.T\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.8590, 2.3916, 1.4863, 1.9616], grad_fn=<SqueezeBackward3>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_2=embedded_sentence[2]\n",
    "query_2=W_q@x_2\n",
    "torch.softmax(query_2@k.T/math.sqrt(d_k),dim=0)@v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self,d_in,d_qk,d_v):\n",
    "        super(SelfAttention,self).__init__()\n",
    "        self.d_in=d_in\n",
    "        self.d_qk=d_qk\n",
    "        torch.manual_seed(42)\n",
    "        self.W_query=torch.nn.Parameter(torch.randn(d_in,d_qk))\n",
    "        self.W_key=torch.nn.Parameter(torch.randn(d_in,d_qk))\n",
    "        self.W_value=torch.nn.Parameter(torch.randn(d_in,d_v))\n",
    "    \n",
    "    def forward(self,input):\n",
    "        embed_in=input\n",
    "        q=embed_in@self.W_query\n",
    "        k=embed_in@self.W_key\n",
    "        v=embed_in@self.W_value\n",
    "        out=torch.softmax(q@k.T/math.sqrt(self.d_qk),dim=0)@v\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0585,  0.1223,  0.0948,  0.0433],\n",
       "        [ 0.0680, -0.2547, -0.1070,  0.0849],\n",
       "        [-1.1127,  0.5667,  0.8144, -0.2457],\n",
       "        [ 0.3429, -0.3360, -0.2759,  0.1794],\n",
       "        [-0.3058,  0.0626,  0.1939, -0.0554],\n",
       "        [11.2437, -4.7408, -7.4778,  3.6876],\n",
       "        [-2.5044,  0.5327,  1.4455, -0.9125],\n",
       "        [ 0.3871, -0.4229, -0.3273,  0.2025],\n",
       "        [-6.3978,  3.2540,  3.9641, -3.6095],\n",
       "        [ 0.0235, -0.0909, -0.0281,  0.0596],\n",
       "        [ 0.4361, -0.1815, -0.2718,  0.1964],\n",
       "        [-0.0658,  0.1768,  0.1211,  0.0490],\n",
       "        [ 0.0238, -0.3170, -0.1049,  0.0770],\n",
       "        [ 3.9775, -1.9090, -2.7097,  1.3658]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self=SelfAttention(3,2,4)\n",
    "self(embedded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self,d_in,d_kq,d_v,num_heads):\n",
    "        super(MultiHeadAttention,self).__init__()\n",
    "        self.d_in=d_in\n",
    "        self.heads=nn.ModuleList(SelfAttention(d_in,d_kq,d_v) for _ in range(num_heads))\n",
    "\n",
    "    def forward(self,input):\n",
    "        \n",
    "        return torch.cat([head(input) for head in self.heads],dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0585,  0.1223,  0.0948,  0.0433, -0.0585,  0.1223,  0.0948,  0.0433,\n",
       "         -0.0585,  0.1223,  0.0948,  0.0433, -0.0585,  0.1223,  0.0948,  0.0433,\n",
       "         -0.0585,  0.1223,  0.0948,  0.0433, -0.0585,  0.1223,  0.0948,  0.0433],\n",
       "        [ 0.0680, -0.2547, -0.1070,  0.0849,  0.0680, -0.2547, -0.1070,  0.0849,\n",
       "          0.0680, -0.2547, -0.1070,  0.0849,  0.0680, -0.2547, -0.1070,  0.0849,\n",
       "          0.0680, -0.2547, -0.1070,  0.0849,  0.0680, -0.2547, -0.1070,  0.0849],\n",
       "        [-1.1127,  0.5667,  0.8144, -0.2457, -1.1127,  0.5667,  0.8144, -0.2457,\n",
       "         -1.1127,  0.5667,  0.8144, -0.2457, -1.1127,  0.5667,  0.8144, -0.2457,\n",
       "         -1.1127,  0.5667,  0.8144, -0.2457, -1.1127,  0.5667,  0.8144, -0.2457],\n",
       "        [ 0.3429, -0.3360, -0.2759,  0.1794,  0.3429, -0.3360, -0.2759,  0.1794,\n",
       "          0.3429, -0.3360, -0.2759,  0.1794,  0.3429, -0.3360, -0.2759,  0.1794,\n",
       "          0.3429, -0.3360, -0.2759,  0.1794,  0.3429, -0.3360, -0.2759,  0.1794],\n",
       "        [-0.3058,  0.0626,  0.1939, -0.0554, -0.3058,  0.0626,  0.1939, -0.0554,\n",
       "         -0.3058,  0.0626,  0.1939, -0.0554, -0.3058,  0.0626,  0.1939, -0.0554,\n",
       "         -0.3058,  0.0626,  0.1939, -0.0554, -0.3058,  0.0626,  0.1939, -0.0554],\n",
       "        [11.2437, -4.7408, -7.4778,  3.6876, 11.2437, -4.7408, -7.4778,  3.6876,\n",
       "         11.2437, -4.7408, -7.4778,  3.6876, 11.2437, -4.7408, -7.4778,  3.6876,\n",
       "         11.2437, -4.7408, -7.4778,  3.6876, 11.2437, -4.7408, -7.4778,  3.6876],\n",
       "        [-2.5044,  0.5327,  1.4455, -0.9125, -2.5044,  0.5327,  1.4455, -0.9125,\n",
       "         -2.5044,  0.5327,  1.4455, -0.9125, -2.5044,  0.5327,  1.4455, -0.9125,\n",
       "         -2.5044,  0.5327,  1.4455, -0.9125, -2.5044,  0.5327,  1.4455, -0.9125],\n",
       "        [ 0.3871, -0.4229, -0.3273,  0.2025,  0.3871, -0.4229, -0.3273,  0.2025,\n",
       "          0.3871, -0.4229, -0.3273,  0.2025,  0.3871, -0.4229, -0.3273,  0.2025,\n",
       "          0.3871, -0.4229, -0.3273,  0.2025,  0.3871, -0.4229, -0.3273,  0.2025],\n",
       "        [-6.3978,  3.2540,  3.9641, -3.6095, -6.3978,  3.2540,  3.9641, -3.6095,\n",
       "         -6.3978,  3.2540,  3.9641, -3.6095, -6.3978,  3.2540,  3.9641, -3.6095,\n",
       "         -6.3978,  3.2540,  3.9641, -3.6095, -6.3978,  3.2540,  3.9641, -3.6095],\n",
       "        [ 0.0235, -0.0909, -0.0281,  0.0596,  0.0235, -0.0909, -0.0281,  0.0596,\n",
       "          0.0235, -0.0909, -0.0281,  0.0596,  0.0235, -0.0909, -0.0281,  0.0596,\n",
       "          0.0235, -0.0909, -0.0281,  0.0596,  0.0235, -0.0909, -0.0281,  0.0596],\n",
       "        [ 0.4361, -0.1815, -0.2718,  0.1964,  0.4361, -0.1815, -0.2718,  0.1964,\n",
       "          0.4361, -0.1815, -0.2718,  0.1964,  0.4361, -0.1815, -0.2718,  0.1964,\n",
       "          0.4361, -0.1815, -0.2718,  0.1964,  0.4361, -0.1815, -0.2718,  0.1964],\n",
       "        [-0.0658,  0.1768,  0.1211,  0.0490, -0.0658,  0.1768,  0.1211,  0.0490,\n",
       "         -0.0658,  0.1768,  0.1211,  0.0490, -0.0658,  0.1768,  0.1211,  0.0490,\n",
       "         -0.0658,  0.1768,  0.1211,  0.0490, -0.0658,  0.1768,  0.1211,  0.0490],\n",
       "        [ 0.0238, -0.3170, -0.1049,  0.0770,  0.0238, -0.3170, -0.1049,  0.0770,\n",
       "          0.0238, -0.3170, -0.1049,  0.0770,  0.0238, -0.3170, -0.1049,  0.0770,\n",
       "          0.0238, -0.3170, -0.1049,  0.0770,  0.0238, -0.3170, -0.1049,  0.0770],\n",
       "        [ 3.9775, -1.9090, -2.7097,  1.3658,  3.9775, -1.9090, -2.7097,  1.3658,\n",
       "          3.9775, -1.9090, -2.7097,  1.3658,  3.9775, -1.9090, -2.7097,  1.3658,\n",
       "          3.9775, -1.9090, -2.7097,  1.3658,  3.9775, -1.9090, -2.7097,  1.3658]],\n",
       "       grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn=MultiHeadAttention(3,2,4,6)\n",
    "attn(embedded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cross_Attention(nn.Module):\n",
    "    def __init__(self,d_in,d_kq,d_v):\n",
    "        super(Cross_Attention,self).__init__()\n",
    "        self.d_in=d_in\n",
    "        self.d_kq=d_kq\n",
    "        torch.manual_seed(42)\n",
    "        self.w_q=torch.nn.Parameter(torch.randn(d_in,d_kq))\n",
    "        self.w_k=torch.nn.Parameter(torch.randn(d_in,d_kq))\n",
    "        self.w_v=torch.nn.Parameter(torch.randn(d_in,d_v))\n",
    "\n",
    "    def forward(self,x1,x2):\n",
    "        q=x1@self.w_q\n",
    "        k=x2@self.w_k\n",
    "        attn_scores=(q@k.T)\n",
    "        attn_weights=torch.softmax(attn_scores/math.sqrt(self.d_kq),dim=-1)\n",
    "        v=x2@self.w_v\n",
    "        out=attn_weights@v\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.8606, -0.1237, -1.0357,  0.4919],\n",
       "        [ 1.8258, -0.2491, -1.0506,  0.5200],\n",
       "        [ 1.8476, -0.0117, -1.0007,  0.4498],\n",
       "        [ 1.8465, -0.2448, -1.0596,  0.5269],\n",
       "        [ 1.8279, -0.1494, -1.0266,  0.4863],\n",
       "        [ 1.8699, -0.3668, -1.1015,  0.5790],\n",
       "        [ 1.8078, -0.0634, -0.9958,  0.4469],\n",
       "        [ 1.8413, -0.2617, -1.0612,  0.5308],\n",
       "        [ 1.8290,  0.0176, -0.9848,  0.4304],\n",
       "        [ 1.8415, -0.1997, -1.0458,  0.5094],\n",
       "        [ 1.8727, -0.1958, -1.0601,  0.5204],\n",
       "        [ 1.8661, -0.1045, -1.0334,  0.4879],\n",
       "        [ 1.8130, -0.2709, -1.0498,  0.5224],\n",
       "        [ 1.8705, -0.3159, -1.0892,  0.5609]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_attn=Cross_Attention(3,2,4)\n",
    "cross_attn(embedded_sentence,torch.rand(8,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalAttention(nn.Module):\n",
    "    def __init__(self,d_in,d_kq,d_v):\n",
    "        super(CausalAttention,self).__init__()\n",
    "\n",
    "        self.d_kq=d_kq\n",
    "        self.w_q=torch.nn.Parameter(torch.randn(d_in,d_kq))\n",
    "        self.w_k=torch.nn.Parameter(torch.randn(d_in,d_kq))\n",
    "        self.w_v=torch.nn.Parameter(torch.randn(d_in,d_v))\n",
    "\n",
    "    def forward(self,x):\n",
    "        q=x@self.w_q\n",
    "        k=x@self.w_k\n",
    "        v=x@self.w_v\n",
    "        attn_score=q@k.T\n",
    "        block_size=attn_score.size()[0]\n",
    "        # mask=torch.tril(torch.ones(block_size,block_size))\n",
    "        # row_sums=mask.sum(dim=1,keepdim=True)\n",
    "        # masked_norm=mask/row_sums\n",
    "\n",
    "        # print(masked_norm)\n",
    "        # attn_weights=torch.softmax(attn_score/math.sqrt(self.d_kq),dim=-1)*masked_norm\n",
    "        mask=torch.triu(torch.ones(block_size,block_size),diagonal=1)\n",
    "        masked=attn_score.masked_fill(mask.bool(),-torch.inf)\n",
    "        print(masked)\n",
    "        attn_weights=torch.softmax(masked/math.sqrt(self.d_kq),dim=-1)\n",
    "        print(attn_weights)\n",
    "        out=attn_weights@v\n",
    "        return out\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0404,    -inf,    -inf,    -inf],\n",
      "        [ 0.0243,  0.0136,    -inf,    -inf],\n",
      "        [-0.0068,  0.0353, -0.2131,    -inf],\n",
      "        [ 0.1780,  0.0615,  0.2613,  0.1035]], grad_fn=<MaskedFillBackward0>)\n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5019, 0.4981, 0.0000, 0.0000],\n",
      "        [0.3455, 0.3559, 0.2986, 0.0000],\n",
      "        [0.2544, 0.2343, 0.2699, 0.2414]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0598,  0.1203, -1.5357, -0.8078],\n",
       "        [ 0.0743,  0.1289, -1.1333, -0.5509],\n",
       "        [ 0.0492,  0.2673, -1.0864, -0.6465],\n",
       "        [ 0.2381,  0.4362, -1.7540, -0.7039]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "causal_attn=CausalAttention(3,2,4)\n",
    "causal_attn(torch.rand(4,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positional Encoding\n",
    "\n",
    "d_model=3\n",
    "\n",
    "PE(pos,2i) = sin(pos/10000**2i/dmodel )\n",
    "PE(pos,2i+1) = cos(pos/10000**2i/dmodel )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(tokens,d_model):\n",
    "    position = torch.arange(len(tokens)).unsqueeze(0).T\n",
    "    div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model))\n",
    "\n",
    "    PE = torch.empty(len(tokens), d_model)\n",
    "    PE[:, 0::2] = torch.sin(position / div_term) \n",
    "    PE[:,1::2]=torch.cos(position/div_term)[:,:int(d_model/2)]\n",
    "    return PE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 3])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input=positional_encoding(sentence_input,3)+embedded_sentence\n",
    "input.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 24])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn(input).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
